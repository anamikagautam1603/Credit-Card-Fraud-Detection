{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show the data in form of table & Importing pandas for data manipulation & Loading the credit card dataset from a CSV file\n",
    "import pandas as pd \n",
    "set = pd.read_csv('creditcard.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  0.105915  0.253844  0.081080    3.67      0  \n",
       "\n",
       "[6 rows x 31 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Show rows according to their choice in the dataset & Display the first 6 rows of the dataset\n",
    "set.head(6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Last 5 rows shows from table\n",
    "\n",
    "# Display the last 5 rows of the dataset\n",
    "set.tail()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Columns:31\n",
      "Number of Rows:284807\n"
     ]
    }
   ],
   "source": [
    "## How many data points and features in our dataset (284807 count of rows, 31 count of columns)\n",
    "\n",
    " # Get the shape of the dataset (number of rows and columns)\n",
    "set.shape \n",
    "\n",
    " # Print number of columns\n",
    "print(\"Number of Columns:{}\".format(set.shape[1])) \n",
    "\n",
    "# Print number of rows\n",
    "print(\"Number of Rows:{}\".format(set.shape[0]))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Information of data\n",
    "\n",
    "# Display information about the DataFrame, including data types and non-null counts\n",
    "set.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# How to check null value\n",
    "# Print the count of null values in each column\n",
    "print(set.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28    Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  0.244964      0  \n",
       "1  0.125895 -0.008983  0.014724 -0.342475      0  \n",
       "2 -0.139097 -0.055353 -0.059752  1.160686      0  \n",
       "3 -0.221929  0.062723  0.061458  0.140534      0  \n",
       "4  0.502292  0.219422  0.215153 -0.073403      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the balance and imbalanced data\n",
    "\n",
    "# Importing StandardScaler for feature scaling\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Creating an instance of StandardScaler \n",
    "sc = StandardScaler()  \n",
    "\n",
    "# Normalize 'Amount' feature using StandardScaler\n",
    "set['Amount'] = sc.fit_transform(pd.DataFrame(set['Amount']))  \n",
    "\n",
    "## These data set range convert into 0 to 1\n",
    "\n",
    " # Display the first few rows after normalization to check changes\n",
    "set.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  0.244964      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724 -0.342475      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  1.160686      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  0.140534      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153 -0.073403      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We can remove the column of time\n",
    "\n",
    " # Drop the 'Time' column as it's not needed for analysis or modeling\n",
    "set = set.drop('Time', axis=1) \n",
    "\n",
    "# Display the first few rows after dropping 'Time'\n",
    "set.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## A duplicated data is there any duplicated data or not\n",
    "\n",
    " # Check if there are any duplicate rows in the DataFrame\n",
    "set.duplicated().any() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 30)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now we can see if duplicated data exists in the dataset \n",
    "\n",
    "# Remove duplicate rows from the DataFrame\n",
    "set = set.drop_duplicates()  \n",
    "\n",
    " # Check shape after removing duplicates to confirm changes\n",
    "set.shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1       473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## If data is balanced and imbalanced data set then after checking then\n",
    "## We can see which type of technique to use; 0 is normal transaction and 1 is fraud transaction\n",
    "\n",
    "# Count occurrences of each class (normal vs. fraud)\n",
    "set['Class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing seaborn for data visualization\n",
    "import seaborn as sns \n",
    "\n",
    "# Importing matplotlib for plotting graphs \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Set plot style to ggplot for better aesthetics\n",
    "plt.style.use('ggplot') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Count and class plot for the dataset using seaborn\n",
    "\n",
    "# Create a count plot for classes in the dataset (0: normal, 1: fraud)\n",
    "sns.countplot(x='Class', data=set)  \n",
    "\n",
    "# Show plot\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First we divide dataset into dependent and independent features x and y\n",
    "\n",
    "# Independent features (all columns except 'Class')\n",
    "x = set.drop('Class', axis=1)  \n",
    "\n",
    " # Dependent variable (target)\n",
    "y = set['Class']   \n",
    "            \n",
    "## Our dataset divided into train test split\n",
    "\n",
    "# Importing train_test_split for splitting datasets\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# Split data into training (80%) and testing (20%) sets with a fixed random state for reproducibility\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=40)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================LogisticRegression===================\n",
      "Accuracy score of LogisticRegression is 0.9992200678359603\n",
      "Precision score of LogisticRegression is 0.9310344827586207\n",
      "Recall score of LogisticRegression is 0.5806451612903226\n",
      "F1 score of LogisticRegression is 0.7152317880794702\n",
      "\n",
      "\n",
      "\n",
      "====================DecisionTreeClassifier===================\n",
      "Accuracy score of DecisionTreeClassifier is 0.9992926196651734\n",
      "Precision score of DecisionTreeClassifier is 0.7647058823529411\n",
      "Recall score of DecisionTreeClassifier is 0.8387096774193549\n",
      "F1 score of DecisionTreeClassifier is 0.8\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Importing machine learning algorithms \n",
    "\n",
    "# Importing Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "\n",
    "# Importing Random Forest model (not used in this snippet)\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "\n",
    "# Importing Support Vector Classifier (not used in this snippet) \n",
    "from sklearn.svm import SVC  \n",
    " \n",
    "# Importing Decision Tree Classifier model                        \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "  \n",
    "# Importing metrics for evaluating model performance    \n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score \n",
    "\n",
    "\n",
    "## All necessary packages are imported for machine learning\n",
    "classifier = {  \n",
    "    # Creating an instance of Logistic Regression classifier\n",
    "    'LogisticRegression': LogisticRegression(), \n",
    "    \n",
    "    # Creating an instance of Decision Tree classifier         \n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier()   \n",
    "}\n",
    "\n",
    "# Training classifiers and evaluating performance metrics on test data\n",
    "for name, classifier in classifier.items():\n",
    "    # Fit model on training data \n",
    "    classifier.fit(x_train, y_train)  \n",
    "    # Make predictions on test data                 \n",
    "    y_pred = classifier.predict(x_test)                \n",
    "    \n",
    "    print(f\"\\n===================={name}===================\")  \n",
    "    print('Accuracy score of', name, 'is', accuracy_score(y_test, y_pred))  \n",
    "    print('Precision score of', name, 'is', precision_score(y_test, y_pred))  \n",
    "    print('Recall score of', name, 'is', recall_score(y_test, y_pred))  \n",
    "    print('F1 score of', name, 'is', f1_score(y_test, y_pred))  \n",
    "    print('\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## UnderSampling means working with minority class \n",
    "\n",
    " # Normal transactions (Class 0)\n",
    "normal = set[set['Class'] == 0]  \n",
    "\n",
    " # Fraud transactions (Class 1)\n",
    "fraud = set[set['Class'] == 1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Get shape of normal transactions \n",
    "normal.shape  \n",
    "\n",
    "# Get shape of fraud transactions \n",
    "fraud.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We need to convert normal data to match fraud transactions count using shape of (473 x features)\n",
    "\n",
    "# Randomly sample normal transactions to have equal representation with fraud transactions\n",
    "normal_sample = normal.sample(n=473)   \n",
    "\n",
    "# Check shape after sampling normal transactions \n",
    "normal_sample.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining the normal and fraud samples into a new DataFrame \n",
    "\n",
    "# Concatenate sampled normal and all fraud transactions into new DataFrame \n",
    "newset = pd.concat([normal_sample, fraud], ignore_index=True)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.234060</td>\n",
       "      <td>-0.826800</td>\n",
       "      <td>2.214116</td>\n",
       "      <td>-2.224890</td>\n",
       "      <td>-1.305846</td>\n",
       "      <td>-0.058365</td>\n",
       "      <td>-1.422690</td>\n",
       "      <td>0.746950</td>\n",
       "      <td>-2.095245</td>\n",
       "      <td>0.445595</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075022</td>\n",
       "      <td>-0.088457</td>\n",
       "      <td>-0.225820</td>\n",
       "      <td>-0.010211</td>\n",
       "      <td>0.284956</td>\n",
       "      <td>-0.268711</td>\n",
       "      <td>-0.024138</td>\n",
       "      <td>-0.083160</td>\n",
       "      <td>-0.298056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452262</td>\n",
       "      <td>-2.678455</td>\n",
       "      <td>-0.501917</td>\n",
       "      <td>-0.750385</td>\n",
       "      <td>-1.839217</td>\n",
       "      <td>-0.829742</td>\n",
       "      <td>0.095113</td>\n",
       "      <td>-0.487032</td>\n",
       "      <td>-1.957841</td>\n",
       "      <td>1.113604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134397</td>\n",
       "      <td>-0.337111</td>\n",
       "      <td>-0.583992</td>\n",
       "      <td>0.444655</td>\n",
       "      <td>0.491294</td>\n",
       "      <td>-0.125225</td>\n",
       "      <td>-0.085911</td>\n",
       "      <td>0.107644</td>\n",
       "      <td>1.935835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.882534</td>\n",
       "      <td>-0.296294</td>\n",
       "      <td>-0.933864</td>\n",
       "      <td>0.038744</td>\n",
       "      <td>-0.045519</td>\n",
       "      <td>-0.441708</td>\n",
       "      <td>-0.022102</td>\n",
       "      <td>-0.096202</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.188069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.358897</td>\n",
       "      <td>-1.233855</td>\n",
       "      <td>0.510326</td>\n",
       "      <td>0.739895</td>\n",
       "      <td>-0.732465</td>\n",
       "      <td>-0.045553</td>\n",
       "      <td>-0.083324</td>\n",
       "      <td>-0.036994</td>\n",
       "      <td>-0.064368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.169669</td>\n",
       "      <td>-0.026631</td>\n",
       "      <td>0.719600</td>\n",
       "      <td>0.918091</td>\n",
       "      <td>-0.622848</td>\n",
       "      <td>-0.330110</td>\n",
       "      <td>-0.219063</td>\n",
       "      <td>0.024248</td>\n",
       "      <td>0.617408</td>\n",
       "      <td>-0.250391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044685</td>\n",
       "      <td>0.158856</td>\n",
       "      <td>-0.011987</td>\n",
       "      <td>0.456815</td>\n",
       "      <td>0.465851</td>\n",
       "      <td>0.449050</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>-0.349231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.707228</td>\n",
       "      <td>0.734191</td>\n",
       "      <td>1.948822</td>\n",
       "      <td>-0.428472</td>\n",
       "      <td>-0.090981</td>\n",
       "      <td>-0.576954</td>\n",
       "      <td>0.899875</td>\n",
       "      <td>-0.063894</td>\n",
       "      <td>-0.153498</td>\n",
       "      <td>-1.037820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198585</td>\n",
       "      <td>-0.531751</td>\n",
       "      <td>-0.074626</td>\n",
       "      <td>0.419413</td>\n",
       "      <td>0.074991</td>\n",
       "      <td>0.124487</td>\n",
       "      <td>0.020425</td>\n",
       "      <td>0.093673</td>\n",
       "      <td>-0.185270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.234060 -0.826800  2.214116 -2.224890 -1.305846 -0.058365 -1.422690   \n",
       "1  0.452262 -2.678455 -0.501917 -0.750385 -1.839217 -0.829742  0.095113   \n",
       "2  1.882534 -0.296294 -0.933864  0.038744 -0.045519 -0.441708 -0.022102   \n",
       "3  1.169669 -0.026631  0.719600  0.918091 -0.622848 -0.330110 -0.219063   \n",
       "4 -0.707228  0.734191  1.948822 -0.428472 -0.090981 -0.576954  0.899875   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.746950 -2.095245  0.445595  ... -0.075022 -0.088457 -0.225820 -0.010211   \n",
       "1 -0.487032 -1.957841  1.113604  ...  0.134397 -0.337111 -0.583992  0.444655   \n",
       "2 -0.096202  0.119506  0.188069  ... -0.358897 -1.233855  0.510326  0.739895   \n",
       "3  0.024248  0.617408 -0.250391  ... -0.044685  0.158856 -0.011987  0.456815   \n",
       "4 -0.063894 -0.153498 -1.037820  ... -0.198585 -0.531751 -0.074626  0.419413   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.284956 -0.268711 -0.024138 -0.083160 -0.298056      0  \n",
       "1  0.491294 -0.125225 -0.085911  0.107644  1.935835      0  \n",
       "2 -0.732465 -0.045553 -0.083324 -0.036994 -0.064368      0  \n",
       "3  0.465851  0.449050  0.001085  0.009392 -0.349231      0  \n",
       "4  0.074991  0.124487  0.020425  0.093673 -0.185270      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows of new balanced dataset \n",
    "newset.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    473\n",
       "1    473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Now we can check new data; it should pass class counts without losing any data.\n",
    "\n",
    "# Check class distribution in new balanced dataset \n",
    "newset['Class'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================LogisticRegression===================\n",
      "Accuracy score of LogisticRegression is 0.9210526315789473\n",
      "Precision score of LogisticRegression is 0.9647058823529412\n",
      "Recall score of LogisticRegression is 0.8723404255319149\n",
      "F1 score of LogisticRegression is 0.9162011173184358\n",
      "\n",
      "\n",
      "\n",
      "====================DecisionTreeClassifier===================\n",
      "Accuracy score of DecisionTreeClassifier is 0.8947368421052632\n",
      "Precision score of DecisionTreeClassifier is 0.9111111111111111\n",
      "Recall score of DecisionTreeClassifier is 0.8723404255319149\n",
      "F1 score of DecisionTreeClassifier is 0.8913043478260869\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Repeat same process for new balanced dataset \n",
    "\n",
    " # Independent features from new balanced dataset \n",
    "x = newset.drop('Class', axis=1)  \n",
    "\n",
    "# Dependent variable from new balanced dataset \n",
    "y = newset['Class']                 \n",
    "\n",
    "# Split new balanced dataset into training (80%) and testing (20%) sets \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=40)  \n",
    "\n",
    "## All necessary packages are imported for machine learning again \n",
    "classifier = { \n",
    "     # Creating an instance of Logistic Regression classifier again  \n",
    "    'LogisticRegression': LogisticRegression(),  \n",
    "    \n",
    "    # Creating an instance of Decision Tree classifier again        \n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier()   \n",
    "}\n",
    "\n",
    "# Training classifiers on balanced dataset and evaluating performance metrics on test data \n",
    "for name, classifier in classifier.items():\n",
    "    \n",
    "     # Fit model on training data \n",
    "    classifier.fit(x_train, y_train) \n",
    "    \n",
    "    # Make predictions on test data                  \n",
    "    y_pred = classifier.predict(x_test)                \n",
    "    \n",
    "    print(f\"\\n===================={name}===================\")  \n",
    "    print('Accuracy score of', name, 'is', accuracy_score(y_test, y_pred))  \n",
    "    print('Precision score of', name, 'is', precision_score(y_test, y_pred))  \n",
    "    print('Recall score of', name, 'is', recall_score(y_test, y_pred))  \n",
    "    print('F1 score of', name, 'is', f1_score(y_test, y_pred))  \n",
    "    print('\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Overlapping data before applying SMOTE \n",
    "x = set.drop('Class', axis=1)   # Independent features from original dataset \n",
    "y = set['Class']                 # Dependent variable from original dataset \n",
    "\n",
    "x.shape   # Check shape of independent features \n",
    "y.shape   # Check shape of dependent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1    275190\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We can apply oversampling using SMOTE \n",
    "\n",
    "# Importing SMOTE for handling imbalanced datasets \n",
    "from imblearn.over_sampling import SMOTE  \n",
    "\n",
    "# Apply SMOTE to resample x and y to balance classes \n",
    "x_res,y_res = SMOTE().fit_resample(x,y)   \n",
    "\n",
    "## Check class distribution after applying SMOTE \n",
    "\n",
    "## Count occurrences of each class after resampling \n",
    "y_res.value_counts()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================LogisticRegression===================\n",
      "Accuracy score of LogisticRegression is 0.9440023256659036\n",
      "Precision score of LogisticRegression is 0.9737692233291421\n",
      "Recall score of LogisticRegression is 0.9128148403358297\n",
      "F1 score of LogisticRegression is 0.9423073323224949\n",
      "\n",
      "\n",
      "\n",
      "====================DecisionTreeClassifier===================\n",
      "Accuracy score of DecisionTreeClassifier is 0.9980377193938733\n",
      "Precision score of DecisionTreeClassifier is 0.9971401162054048\n",
      "Recall score of DecisionTreeClassifier is 0.9989482655448165\n",
      "F1 score of DecisionTreeClassifier is 0.9980433719223871\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we apply machine learning algorithms to resampled data \n",
    "\n",
    "# Split resampled data into training (80%) and testing (20%) sets \n",
    "x_train,x_test,y_train,y_test=train_test_split(x_res,y_res,test_size=0.2,random_state=40)  \n",
    "\n",
    "## All necessary packages are imported for machine learning again \n",
    "classifier = {  \n",
    "    ## Creating an instance of Logistic Regression classifier again\n",
    "    'LogisticRegression': LogisticRegression(),          \n",
    "    \n",
    "    ## Creating an instance of Decision Tree classifier again \n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier()   \n",
    "}\n",
    "\n",
    "# Training classifiers on resampled dataset and evaluating performance metrics on test data \n",
    "for name,classifier in classifier.items():\n",
    "    \n",
    "     ## Fit model on training data \n",
    "    classifier.fit(x_train,y_train)                  \n",
    "    \n",
    "    ## Make predictions on test data \n",
    "    y_pred=classifier.predict(x_test)                \n",
    "    \n",
    "    print(f\"\\n===================={name}===================\")  \n",
    "    print('Accuracy score of',name,'is',accuracy_score(y_test,y_pred))   \n",
    "    print('Precision score of',name,'is',precision_score(y_test,y_pred))   \n",
    "    print('Recall score of',name,'is',recall_score(y_test,y_pred))   \n",
    "    print('F1 score of',name,'is',f1_score(y_test,y_pred))   \n",
    "    print('\\n')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Decision Tree Classifier again if needed later \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "## Importing joblib for saving models   \n",
    "import joblib   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Decision Tree Classifier \n",
    "dtc = DecisionTreeClassifier(random_state=42)  \n",
    "\n",
    "# Fit the model on training data \n",
    "dtc.fit(x_train,y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_tree_model.pkl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model to a file \n",
    "joblib.dump(dtc,'decision_tree_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file (when needed) \n",
    "loaded_model = joblib.load('decision_tree_model.pkl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the loaded model on the test set \n",
    "y_pred = loaded_model.predict(x_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "Accuracy: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n",
      "Predictions on the test set: [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model's performance using various metrics \n",
    "accuracy = accuracy_score(y_test,y_pred)   \n",
    "precision = precision_score(y_test,y_pred)   \n",
    "recall = recall_score(y_test,y_pred)   \n",
    "f1 = f1_score(y_test,y_pred)   \n",
    "\n",
    "# Print evaluation metrics \n",
    "print(\"Model Evaluation Metrics:\")   \n",
    "print(f\"Accuracy: {accuracy:.2f}\")   \n",
    "print(f\"Precision: {precision:.2f}\")   \n",
    "print(f\"Recall: {recall:.2f}\")   \n",
    "print(f\"F1 Score: {f1:.2f}\")   \n",
    "\n",
    "# Optionally display predictions if needed \n",
    "print(\"Predictions on the test set:\",y_pred)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
